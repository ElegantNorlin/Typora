* **Joint Learning of Social Groups, Individuals Action and Sub-group Activities in Videos（视频中的社会群体、个人行为、和子群体行为的联合学习）**

  > 框架整体架构

  <img src="https://gitee.com/wanwanzh/imagebed/raw/master/pictures/image-20210308165427030.png" alt="image-20210308165427030" style="zoom:67%;" />  

  * 使用I3D作为一种先进的时空编码特征提取器表示个人视频。(论文：A video dataset of spatiotemporally localized atomic visual actions.)
  * 使用Self-attention模块完善个人的特征表示(源自Attention is all you need论文)。
  * 使用图注意模块模拟个体间的互动和联系（论文：Graph Attention Network）。

  **总结：**通过整合I3D主干网、自我注意模块和图形注意模块，我们提出了一个端到端的群体活动识别任务框架。

* **Fast Collective Activity Recognition（弱监督）（弱监督下的快速集体活动识别）**

  #### 融合MPs和KVI的识别

  ##### 通过运动模式（MPs）识别群体活动

  我们利用双流3DCNN结构将全局和局部的运动模式结合起来进行群体活动识别。两个流中的网络结构是相同的。每个3D CNN结构都有五个3D卷积层，分别有64、128、128、256、256个**feature map**，然后是三个全连接层的维度2048、2048和活动类数（6）的层。批处理标准化层在每-一个卷积层和前两个完全连接层之后进行连接。除了第一个池化层的内核大小被设置为2 X2X1外，我们在所有核大小为2X2X2的池化层中都使用了最大池化。给定一个视频片段，全局运动和局部数据被依次输入到相应的网络流中。输出的是6个小组活动(3分、罚球、上篮、2分、扣篮和抢断)的**概率分布**。

  ##### 使用关键的视觉信息（KVI）预测成功/失败

  成功或失败可以通过球是否随着网的运动而落入篮框来有效地识别，如图2所示。基于这一点，构建了一种关键的基于视觉信息的成功失败预测方案。检测篮区域，提取篮区域的外观特征，进行成功/失败预测。为了提高实时性，采用SSD单弹检测(Single Shot Detection, SSD)模型对篮筐进行检测，利用AlexNet结构对篮筐进行外观特征提取。此外，考虑到球在篮筐中的成功只能持续几帧的事实，我们设计了一种策略，只要球在篮筐中的一帧被预测成功，就被认为是成功的，否则就被认为是失败的。

  ##### 两条管道融合

  从两条管道中，我们可以得到群组活动和成功/失败的预测结果，我们把两个结果编码成二进制向量。概率最高的元素被赋值为1，其他元素被赋值为0。然后利用Kronecker乘积运算将这两个结果融合为语义识别结果。

  或许可以这样理解：

  * 群组活动结果的概率最高的元素编码为1

  * 成功/失败概率最高的元素编码为1

  * 将编码好的结果带入**kronecker**公示

    群组活动编码一定是1，成功/失败的编码可能为1，也可能为0.

    > 有以下两种结果
    >
    > * 结果为1表征群组活动进行了且球进了
    > * 结果为0表征群组活动进行了，但是球没进（包括抢断活动）

  **kronecker**（克罗内克符号）

* **Progressive_Relation_Learning_for_Group_Activity_Recognition_CVPR_2020_paper（群体活动识别的渐进关系学习）**

  > 论文解决问题：

  * 并不是所有现有的关系都与群体活动相关，其中包含了很多伪造声耦合来的边缘，因此无法确定某一特定的关系是否与群体相关。
  * 在研究群体活动中，通常只有几个关键帧中的几个动作定义了群体活动，现有的运用“自我注意”机制关注重要人物和关键帧的方法仅限于粗个体（个人）水平，并没有深入到细粒度的水平。

  > 论文的亮点：

  * 论文基于强化学习

  * 提出了新的用于群体活动分析的渐进关系学习框架
  * 除了在个体层次上提取群体相关信息外，还提出了RG agent来逐步发现细粒度关系层次上的群体相关语义关系。
  * 提出了一种FD代理，过滤用于构建高层语义关系图的底层时空特征框架。

* **Transformers_for_Group_Activity_Recognition_CVPR_2020_paper**

  > 论文解决问题：

  * 以前的论文大部分都是明确地根据actor的位置来模拟这些空间和时间关系，此篇论文题了一种隐式的时空模型来进行群组活动识别。

  > 论文的亮点：

  * 提出了用于群体活动识别的transformer网络。

  **整个网络分为三个阶段：**

  * 参与者的特征提取、群体活动的融合和聚合。在这一阶段应用了2D姿态网络和3DCNN网络来获得每个actor的静态和动态表示。
  * 应用一层transformer网络。
  * 使用融合策略前后的transfoemer网络。

* **Social Adaptive Module for Weakly-supervised Group Activity Recognition（弱监督群体活动识别的社交自适应模块）**

  > 论文解决的问题：

  * 以往的方法对每帧中人数的变化很敏感，需要明确人员的位置，在实际应用中收到限制。

  > 论文的亮点：

  * 为群组活动识别（GAR）引入了弱监督设置，弱监督模块引入了SAM自适应的选取有效帧用于GAR.

* **Skeleton-based Relational Reasoning for Group Activity Analysis（群体活动分析的基于骨架的关系推理）**

  > 论文解决问题：

  * 从早期提出的基于局部描述符和手工特征的解决方案[6,9,10]。对于基于深度学习的方法，使用卷积神经网络(CNNs)提取底层特征，并耦合递归神经网络(RNNs)进行时间推理[7,11,12,13]。最近的研究从基于图的角度解决了这个问题，使用这种表示来建模群体个体和联系，然后使用诸如图卷积网络(GCNs)等技术来推断他们的关系和互动，根本不关注交互，要么在其框架的更高层次上进行推理，因此它们缺乏在更低层次、更接近输入特性的层次上学习关系的手段。

  > 论文提出框架的思路：

  <img src="https://gitee.com/wanwanzh/imagebed/raw/master/pictures/image-20210312102544684.png" alt="image-20210312102544684" style="zoom:67%;" /> 

  

  

  ![image-20210312102140180](https://gitee.com/wanwanzh/imagebed/raw/master/pictures/image-20210312102140180.png) 

  * 提出了名为GIRN-群组交互关系网络。利用骨架信息来学习个体之间的直接交互，一个直接在关节空间坐标上运行的架构，利用这种表示来推断不同个体之间的交互。通过一对关系网络，我们的架构可以学习不同的关系，以区分正在发生的群体活动。通过有意识地选择将专门为关系模块提供哪些对，可以引导模块专门化特定类型的关系。一个模块侧重于从单个个体学习关节之间的关系，而另一个模块侧重于从不同的人学习关节之间的关系。我们还尝试了另一个可能的模块，专门研究人类关节和感兴趣的对象(如排球)之间的关系。

* **Mining Semantics-Preserving Attention for Group Activity（挖掘语义保留注意的群体活动识别）**

  > 论文框架流程：

  ![image-20210312135913508](https://gitee.com/wanwanzh/imagebed/raw/master/pictures/image-20210312135913508.png) 

  * 提出了一种语义保持的师生模型用于视频群体活动识别，该模型可以挖掘语义保持的注意，自动寻找关键人物并剔除误导人物。具体来说：先学习一个具有典型注意机制的高性能模型（即教师网络），将个体行为映射到语义域的群体活动。接下来，开发一个一个相似的模型（即学生网络），从视觉域的个体行为预测群体活动。

* **Indoor Group Activity Recognition using Multi-Layered HMMs（使用多层HMM进行室内群组活动识别）**

  该论文适用于HHI（人人交互，仅限于拥抱、握手、打招呼）和HOI（人物交互）

  > 论文的亮点：

  * 论文提出了一种基于本体的GAR模型，该模型具有正确的推理能力，用于对群体活动进行识别和分类。
  * 提出了一种多层隐马尔可夫模型（HMM）来识别不同层次的抽象遗传算法。

* **Learning Actor Relation Graphs for Group Activity Recognition(学习行动者关系图的群体活动识别)**

  > 群组活动识别的思路：

  * 提出了一个行动者关系图（ARG），通过图卷积网络，ARG中的连接可以端到端的从群体活动视频中自动学习。为了在视频中更有效的建模，我们提出了两种简化ARG的变体：**空间定位ARG** 和 **时间随机ARG** 。
  * 将最初提出用于半监督学习的图卷积网络（GCN）更改为**具有稀疏时间采样策略（随即丢弃若干帧，只保留一些）**的GCN。

  ![image-20210311190628641](/Users/wanwan/Library/Application Support/typora-user-images/image-20210311190628641.png) 

   

  > 框架实现细节

  * 群体活动识别：

    * 先使用Inception-v3位每帧提取多尺度特征图。
    * 使用ROIAlign从帧特征度提取每个行动者边界框特征。
    * 对齐特征之后执行FC层，一伙的每个行动者d维外观特征向量。
    * 选取的k帧中盒子的总数为N，我们用一个N * d矩阵X来表示行动者的特征向量。

  * 构建行动者关系图

    * 图的定义：

      图中的一个结点对应一个行动者

      <img src="https://gitee.com/wanwanzh/imagebed/raw/master/pictures/image-20210312095701455.png" alt="image-20210312095701455" style="zoom:67%;" />  

      N是行动者数量

      xia是行动者外貌特征

      xis是行动者盒子的中心坐标

      图中Gij表示行动者j的特征对行动者I的重要性。

    * 对外观特征和位置信息进行建模

  * 图推理与训练

    这个模块使用GCN（图卷积网络）。简单的说GCN就是将一个图作为输入，对结构执行计算，并返回一个图作为输出。

* **Improved Actor Relation Graph based Group Activity Recognition**

  > 论文的亮点：

  * 使用了归一化互相关系（NCC），和绝对差和（SAD）来计算成对的外观相似度，并建立行动者关系图，以允许图卷积网络学习如何分类群体活动识别。

* **Hierarchical Graph-based Cross Inference Network for group activity recognition**

  > 论文亮点：

  * 提出了一个框架（HIGCIN）用于构建和整合群体活动中的多层信息和潜在依赖关系。

  * 引入了一个通用的交叉推理模块（CIB），它赋予了HIGCIN捕捉隐藏在群体活动中的共生时空依赖性的能力。

* **Group Activity Recognition by Using Effective（利用有效的时空注意多模态关系表征进行群体活动识别）**

  > 论文的亮点：

  * 提出了一种算法：ATAL算法，算法基于注意力机制进一步获取融合的序列极特征并推断最终结果。
  * 提出了一种表达物体间关系和运动信息的新方法，用于群体活动识别。
  * 利用GRUs提出了opt-GRU和基于关系gru的推理模型。

* **Fusing Motion Patterns and Key Visual Information for Semantic Event Recognition in Basketball Videos（篮球视频中的融合运动模式和关键视觉信息的语义事件识别）**

  > 论文解决问题：

  * 在篮球视频中（可以推广到其他体育活动中），赛场、球员的着装等原因，视觉外观的表征往往不可靠，个体之间的运动遮挡的程度也决定了检测的难度，显然这种只关注局部信息是不可靠的。结合全局信息应该会更可靠一些。

  > 论文的亮点：

  * 提出了运动模式和关键视觉信息分离的框架：视频帧同时输入到两个管道中，第一个管道是分离全局运动和局部运动，并利用双流3DCNN模块来表示运动模式，用于群体活动识别。第二个管道中，使用CNN模型从检测到的篮筐区域提取出KVI，用于表示进攻成功或者失败。结合群体活动识别和进攻的成功与否，来推断篮球视频中的语义事件。（语义事件：用于表示用户动作的事件。）


