### Social Adaptive Module for Weakly-supervised Group Activity Recognition（弱监督群体活动识别的社交自适应模块）

#### 摘要

这篇文章提出了一种弱监督群体活动识别任务，与传统的小组活动识别不同之处在于只提供视频级别的标签，而非提供每一帧中的目标人物（例如，每个人的ground truth边界框和个人行为标签，甚至人与人互动的标签）。为了从弱监督中挖掘有用信息，设计了一个社会适应模块（SAM--Social Adaptive Module）来从数据中推理关键人物和框架。

#### 介绍

> 论文解决的问题：

* 以往的全监督方法在群体识别中确实取得了很好的效果，但是这些方法需要人层面的标注（比如每个人的边界框和个人行为标签，甚至人和人互动的标签）

* 以往的方法对每帧中人数的变化很敏感，需要明确人员的位置，在实际应用中收到限制。

![image-20210306170618412](/Users/wanwan/Library/Application Support/typora-user-images/image-20210306170618412.png) 

上图为全监督方法在群体活动中的表现，我们可以看到出了框中的运动员还框出了对群体活动无用的用户。也能从21=5+16看出16个异常值，5个正常值。这些异常值在实际应用中是无用的，额外的消耗性能。在实际应用中可能会受到限制。



> 论文的亮点：

* 为GAR提供了视频级别标签的弱监督设置，而不需要框出每个人。
* 为群组活动识别（GAR）引入了弱监督设置，弱监督模块引入了SAM自适应的选取有效帧用于GAR，或者说自适应的寻找有效的人物级别和框架级别的表征。

#### 弱监督的群体活动识别

* 弱监督GAR的NBA数据集

  引入了一个新的基于视频的数据集——NBA数据集。并没有对每个队员进行注释，只对每个剪辑的视频活动做标签。

  完全监督的数据集设置需要k个盒子（盒子就是我们人工加的框boxes），k个动作和一个活动标签，而弱监督设置只需要一组活动标签。

  论文一共收集了181场NBA视频，分辨率为1920✖️1080。用上述方法将视频分成6秒的片段，将视频设置为12fps。此外，还删除了一些不需要的片段，例如：特写镜头、即时回放，最终得到9172个视频片段。随机选择7624个片段进行训练，1548个片段进行测试。

#### 方法

⚠️：

![image-20210307112504430](https://gitee.com/wanwanzh/imagebed/raw/master/pictures/image-20210307112504430.png) 

> * F()空间建模函数
> * O()时间建模函数
> * D(V)每个框架的建议（也就是框出的ROI区域）
> * W表示参数为W的CNN提取V帧的卷积特征图
> * V表示要卷积的帧数

* 通过社会关系挖掘关键实例

* 社会适应模块（SAM）

  ![image-20210307120718706](/Users/wanwan/Library/Application Support/typora-user-images/image-20210307120718706.png) 

  
